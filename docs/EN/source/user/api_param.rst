API parameter
==========================


:code:`GET /health`
~~~~~~~~~~~~~~~~~~~~
:code:`HEAD /health`
~~~~~~~~~~~~~~~~~~~~
:code:`GET /healthz`
~~~~~~~~~~~~~~~~~~~~

Get the current server running status

**Usage Examples**： 

.. code-block:: console

    $ curl http://0.0.0.0:8080/health


**Output Examples**：

.. code-block:: python

    {"message":"Ok"}



:code:`GET /token_load`
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Get the current server token usage

**Usage Examples**： 

.. code-block:: console

    $ curl http://0.0.0.0:8080/token_load


**Output Examples**：

.. code-block:: python

    {"current_load":0.0,"logical_max_load":0.0,"dynamic_max_load":0.0}


:code:`POST /generate`
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Calling the model to implement text completion

**Usage Examples**： 

.. code-block:: console

    $ curl http://localhost:8080/generate \
    $ -H "Content-Type: application/json" \
    $ -d '{
    $      "inputs": "What is AI?",
    $      "parameters":{
    $        "max_new_tokens":17,
    $        "frequency_penalty":1
    $      },
    $      "multimodal_params":{}
    $     }'

.. tip::

    For the contents of parameters, refer to :ref:`parameters`, for the contents of multimodal_params, refer to :ref:`MultimodalParams`


**Output Examples**：

.. code-block:: python

    {"generated_text": [" What is the difference between AI and ML? What are the differences between AI and ML"], "count_output_tokens": 17, "finish_reason": "length", "prompt_tokens": 4}


:code:`POST /generate_stream`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Streaming returns text completion results


**Usage Examples**： 

.. code-block:: console

    $ curl http://localhost:8080/generate_stream \
    $ -H "Content-Type: application/json" \
    $ -d '{
    $      "inputs": "What is AI?",
    $      "parameters":{
    $        "max_new_tokens":17,
    $        "frequency_penalty":1
    $      },
    $      "multimodal_params":{}
    $     }'

**Output Examples**：

::

    data:{"token": {"id": 3555, "text": " What", "logprob": -1.8383026123046875, "special": false, "count_output_tokens": 1, "prompt_tokens": 4}, "generated_text": null, "finished": false, "finish_reason": null, "details": null}

    data:{"token": {"id": 374, "text": " is", "logprob": -0.59185391664505, "special": false, "count_output_tokens": 2, "prompt_tokens": 4}, "generated_text": null, "finished": false, "finish_reason": null, "details": null}

    data:{"token": {"id": 279, "text": " the", "logprob": -1.5594439506530762, "special": false, "count_output_tokens": 3, "prompt_tokens": 4}, "generated_text": null, "finished": true, "finish_reason": "length", "details": null}


:code:`POST /get_score`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Reward model, get the dialogue score.

**Usage Examples**： 

.. code-block:: python

    import json
    import requests

    query = "<|im_start|>user\nHello! What's your name?<|im_end|>\n<|im_start|>assistant\nMy name is InternLM2! A helpful AI assistant. What can I do for you?<|im_end|>\n<|reward|>"

    url = "http://127.0.0.1:8080/get_score"
    headers = {'Content-Type': 'application/json'}

    data = {
        "chat": query,
        "parameters": {
            "frequency_penalty":1
        }
    }
    response = requests.post(url, headers=headers, data=json.dumps(data))

    if response.status_code == 200:
        print(f"Result: {response.json()}")
    else:
        print(f"Error: {response.status_code}, {response.text}")

**Output Examples**：

::

    Result: {'score': 0.4892578125, 'prompt_tokens': 39, 'finish_reason': 'stop'}


:code:`POST /v1/chat/completions`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

openai type api， see `openai API docs <https://platform.openai.com/docs/api-reference/introduction>`_  for details.
